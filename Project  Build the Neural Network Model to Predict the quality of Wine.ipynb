{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project : Build the Model through Neural Network To Predict The Quality of Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv('Wine Quality.csv')\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    681\n",
       "6    638\n",
       "7    199\n",
       "4     53\n",
       "8     18\n",
       "3     10\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'].replace({3: 0, 4 : 0, 5 : 0, 6 : 1, 7 : 1, 8 : 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    855\n",
       "0    744\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename (columns = {'fixed acidity' : 0, 'volatile acidity':1, 'citric acid':2, 'residual sugar':3,\n",
    "       'chlorides':4, 'free sulfur dioxide':5, 'total sulfur dioxide':6, 'density':7,\n",
    "       'pH':8, 'sulphates':9, 'alcohol':10, 'quality':11}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3      4     5     6       7     8     9    10  11\n",
       "0   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   0\n",
       "1   7.8  0.88  0.00  2.6  0.098  25.0  67.0  0.9968  3.20  0.68  9.8   0\n",
       "2   7.8  0.76  0.04  2.3  0.092  15.0  54.0  0.9970  3.26  0.65  9.8   0\n",
       "3  11.2  0.28  0.56  1.9  0.075  17.0  60.0  0.9980  3.16  0.58  9.8   1\n",
       "4   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    855\n",
       "0    744\n",
       "Name: 11, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[11].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       1599 non-null   float64\n",
      " 1   1       1599 non-null   float64\n",
      " 2   2       1599 non-null   float64\n",
      " 3   3       1599 non-null   float64\n",
      " 4   4       1599 non-null   float64\n",
      " 5   5       1599 non-null   float64\n",
      " 6   6       1599 non-null   float64\n",
      " 7   7       1599 non-null   float64\n",
      " 8   8       1599 non-null   float64\n",
      " 9   9       1599 non-null   float64\n",
      " 10  10      1599 non-null   float64\n",
      " 11  11      1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.4  ,  0.7  ,  0.   , ...,  0.56 ,  9.4  ,  0.   ],\n",
       "       [ 7.8  ,  0.88 ,  0.   , ...,  0.68 ,  9.8  ,  0.   ],\n",
       "       [ 7.8  ,  0.76 ,  0.04 , ...,  0.65 ,  9.8  ,  0.   ],\n",
       "       ...,\n",
       "       [ 6.3  ,  0.51 ,  0.13 , ...,  0.75 , 11.   ,  1.   ],\n",
       "       [ 5.9  ,  0.645,  0.12 , ...,  0.71 , 10.2  ,  0.   ],\n",
       "       [ 6.   ,  0.31 ,  0.47 , ...,  0.66 , 11.   ,  1.   ]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = data[:,0:11]\n",
    "y = data[:,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=11, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "160/160 [==============================] - 2s 4ms/step - loss: 1.8474 - accuracy: 0.5172\n",
      "Epoch 2/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.6628 - accuracy: 0.6304\n",
      "Epoch 3/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.6442 - accuracy: 0.6423\n",
      "Epoch 4/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.6331 - accuracy: 0.6410\n",
      "Epoch 5/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.6253 - accuracy: 0.6535\n",
      "Epoch 6/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.6149 - accuracy: 0.6617\n",
      "Epoch 7/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.6067 - accuracy: 0.6617\n",
      "Epoch 8/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.6025 - accuracy: 0.6798\n",
      "Epoch 9/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5979 - accuracy: 0.6748\n",
      "Epoch 10/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5898 - accuracy: 0.6773\n",
      "Epoch 11/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5816 - accuracy: 0.6904\n",
      "Epoch 12/150\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.5743 - accuracy: 0.7061\n",
      "Epoch 13/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5792 - accuracy: 0.6967\n",
      "Epoch 14/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5658 - accuracy: 0.7048\n",
      "Epoch 15/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5626 - accuracy: 0.6992\n",
      "Epoch 16/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5562 - accuracy: 0.7104\n",
      "Epoch 17/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5541 - accuracy: 0.7148\n",
      "Epoch 18/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5579 - accuracy: 0.7092\n",
      "Epoch 19/150\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.5530 - accuracy: 0.7123\n",
      "Epoch 20/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5485 - accuracy: 0.7154\n",
      "Epoch 21/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5528 - accuracy: 0.7161\n",
      "Epoch 22/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5416 - accuracy: 0.7142\n",
      "Epoch 23/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5476 - accuracy: 0.7230\n",
      "Epoch 24/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5361 - accuracy: 0.7411: 1s - los\n",
      "Epoch 25/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5380 - accuracy: 0.7305\n",
      "Epoch 26/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5375 - accuracy: 0.7236\n",
      "Epoch 27/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5341 - accuracy: 0.7380\n",
      "Epoch 28/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5361 - accuracy: 0.7248\n",
      "Epoch 29/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5359 - accuracy: 0.7342\n",
      "Epoch 30/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5416 - accuracy: 0.7223\n",
      "Epoch 31/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5330 - accuracy: 0.7298\n",
      "Epoch 32/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5332 - accuracy: 0.7242\n",
      "Epoch 33/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5330 - accuracy: 0.7311\n",
      "Epoch 34/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5263 - accuracy: 0.7361\n",
      "Epoch 35/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5298 - accuracy: 0.7298\n",
      "Epoch 36/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5296 - accuracy: 0.7330\n",
      "Epoch 37/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5257 - accuracy: 0.7367\n",
      "Epoch 38/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5289 - accuracy: 0.7330\n",
      "Epoch 39/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5262 - accuracy: 0.7386\n",
      "Epoch 40/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5237 - accuracy: 0.7305\n",
      "Epoch 41/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5244 - accuracy: 0.7305\n",
      "Epoch 42/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5192 - accuracy: 0.7448\n",
      "Epoch 43/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5215 - accuracy: 0.7355\n",
      "Epoch 44/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5213 - accuracy: 0.7330\n",
      "Epoch 45/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5186 - accuracy: 0.7355\n",
      "Epoch 46/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5197 - accuracy: 0.7367\n",
      "Epoch 47/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5184 - accuracy: 0.7480\n",
      "Epoch 48/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5206 - accuracy: 0.7417\n",
      "Epoch 49/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5148 - accuracy: 0.7380\n",
      "Epoch 50/150\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.5178 - accuracy: 0.7448\n",
      "Epoch 51/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5182 - accuracy: 0.7430\n",
      "Epoch 52/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5185 - accuracy: 0.7373\n",
      "Epoch 53/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5223 - accuracy: 0.7298\n",
      "Epoch 54/150\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.5186 - accuracy: 0.7286\n",
      "Epoch 55/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5133 - accuracy: 0.7492\n",
      "Epoch 56/150\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.5148 - accuracy: 0.7492\n",
      "Epoch 57/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5240 - accuracy: 0.7342\n",
      "Epoch 58/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5199 - accuracy: 0.7461\n",
      "Epoch 59/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5142 - accuracy: 0.7436\n",
      "Epoch 60/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5119 - accuracy: 0.7498\n",
      "Epoch 61/150\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.5147 - accuracy: 0.74 - 1s 5ms/step - loss: 0.5165 - accuracy: 0.7417\n",
      "Epoch 62/150\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.5110 - accuracy: 0.7486\n",
      "Epoch 63/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5160 - accuracy: 0.7411\n",
      "Epoch 64/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5099 - accuracy: 0.7542\n",
      "Epoch 65/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5146 - accuracy: 0.7430\n",
      "Epoch 66/150\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.5114 - accuracy: 0.7442\n",
      "Epoch 67/150\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.5224 - accuracy: 0.7273\n",
      "Epoch 68/150\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.5110 - accuracy: 0.7386\n",
      "Epoch 69/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5138 - accuracy: 0.7367\n",
      "Epoch 70/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5119 - accuracy: 0.7480\n",
      "Epoch 71/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5094 - accuracy: 0.7473\n",
      "Epoch 72/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5078 - accuracy: 0.7417\n",
      "Epoch 73/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5066 - accuracy: 0.7461\n",
      "Epoch 74/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5124 - accuracy: 0.7448\n",
      "Epoch 75/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5070 - accuracy: 0.7548\n",
      "Epoch 76/150\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.5125 - accuracy: 0.7517: 0s - loss: 0\n",
      "Epoch 77/150\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.5066 - accuracy: 0.7555\n",
      "Epoch 78/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5040 - accuracy: 0.7486\n",
      "Epoch 79/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5086 - accuracy: 0.7480\n",
      "Epoch 80/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5050 - accuracy: 0.7480\n",
      "Epoch 81/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5043 - accuracy: 0.7517\n",
      "Epoch 82/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5074 - accuracy: 0.7411\n",
      "Epoch 83/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5056 - accuracy: 0.7436\n",
      "Epoch 84/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5096 - accuracy: 0.7511\n",
      "Epoch 85/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5032 - accuracy: 0.7467: 0s - los\n",
      "Epoch 86/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5086 - accuracy: 0.7492\n",
      "Epoch 87/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5039 - accuracy: 0.7511\n",
      "Epoch 88/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4989 - accuracy: 0.7580\n",
      "Epoch 89/150\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.5055 - accuracy: 0.7580\n",
      "Epoch 90/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5062 - accuracy: 0.7523\n",
      "Epoch 91/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5066 - accuracy: 0.7492\n",
      "Epoch 92/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5013 - accuracy: 0.7617\n",
      "Epoch 93/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5048 - accuracy: 0.7492\n",
      "Epoch 94/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4997 - accuracy: 0.7542\n",
      "Epoch 95/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4971 - accuracy: 0.7536\n",
      "Epoch 96/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4976 - accuracy: 0.7642\n",
      "Epoch 97/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5001 - accuracy: 0.7561\n",
      "Epoch 98/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5033 - accuracy: 0.7467\n",
      "Epoch 99/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5007 - accuracy: 0.7536\n",
      "Epoch 100/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5033 - accuracy: 0.7473\n",
      "Epoch 101/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4963 - accuracy: 0.7536\n",
      "Epoch 102/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5015 - accuracy: 0.7542\n",
      "Epoch 103/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5041 - accuracy: 0.7517\n",
      "Epoch 104/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5062 - accuracy: 0.7511\n",
      "Epoch 105/150\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.4966 - accuracy: 0.7523\n",
      "Epoch 106/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4993 - accuracy: 0.7580\n",
      "Epoch 107/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5015 - accuracy: 0.7511\n",
      "Epoch 108/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4958 - accuracy: 0.7567\n",
      "Epoch 109/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4982 - accuracy: 0.7536\n",
      "Epoch 110/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5095 - accuracy: 0.7386\n",
      "Epoch 111/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5110 - accuracy: 0.7517\n",
      "Epoch 112/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4980 - accuracy: 0.7636\n",
      "Epoch 113/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4990 - accuracy: 0.7511\n",
      "Epoch 114/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5013 - accuracy: 0.7461\n",
      "Epoch 115/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4947 - accuracy: 0.7598\n",
      "Epoch 116/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4987 - accuracy: 0.7624\n",
      "Epoch 117/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4981 - accuracy: 0.7548\n",
      "Epoch 118/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4961 - accuracy: 0.7505\n",
      "Epoch 119/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.4983 - accuracy: 0.7548\n",
      "Epoch 120/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4998 - accuracy: 0.7611\n",
      "Epoch 121/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.4948 - accuracy: 0.7530\n",
      "Epoch 122/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4903 - accuracy: 0.7592\n",
      "Epoch 123/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5011 - accuracy: 0.7555\n",
      "Epoch 124/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4967 - accuracy: 0.7605\n",
      "Epoch 125/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5037 - accuracy: 0.7486\n",
      "Epoch 126/150\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.4979 - accuracy: 0.7548\n",
      "Epoch 127/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4996 - accuracy: 0.7555\n",
      "Epoch 128/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4921 - accuracy: 0.7567\n",
      "Epoch 129/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4983 - accuracy: 0.7473\n",
      "Epoch 130/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5020 - accuracy: 0.7523: 0s - loss: 0.4982 - accu\n",
      "Epoch 131/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4931 - accuracy: 0.7580\n",
      "Epoch 132/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4941 - accuracy: 0.7649: 0s - loss: 0.4961 \n",
      "Epoch 133/150\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.5042 - accuracy: 0.7511: 0s - loss: 0\n",
      "Epoch 134/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4971 - accuracy: 0.7461\n",
      "Epoch 135/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4965 - accuracy: 0.7636\n",
      "Epoch 136/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4927 - accuracy: 0.7511\n",
      "Epoch 137/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4999 - accuracy: 0.7630\n",
      "Epoch 138/150\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.4933 - accuracy: 0.7511: 0s - loss: 0.4953 - accuracy: 0.\n",
      "Epoch 139/150\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.4947 - accuracy: 0.7567\n",
      "Epoch 140/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4926 - accuracy: 0.7661\n",
      "Epoch 141/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4900 - accuracy: 0.7580\n",
      "Epoch 142/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5003 - accuracy: 0.7542\n",
      "Epoch 143/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4941 - accuracy: 0.7624\n",
      "Epoch 144/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4941 - accuracy: 0.7498\n",
      "Epoch 145/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4974 - accuracy: 0.7580\n",
      "Epoch 146/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4988 - accuracy: 0.7555\n",
      "Epoch 147/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4943 - accuracy: 0.7605\n",
      "Epoch 148/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4923 - accuracy: 0.7649\n",
      "Epoch 149/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4907 - accuracy: 0.7655\n",
      "Epoch 150/150\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.4929 - accuracy: 0.7542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3b75c978>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 4ms/step - loss: 0.4784 - accuracy: 0.7642\n",
      "Accuracy: 76.42\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make probability predictions with the model\n",
    "predictions = model.predict(X)\n",
    "# round predictions \n",
    "rounded = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions with the model\n",
    "predictions = (model.predict(X) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.4, 0.7, 0.0, 1.9, 0.076, 11.0, 34.0, 0.9978, 3.51, 0.56, 9.4] => 0 (expected 0)\n",
      "[7.8, 0.88, 0.0, 2.6, 0.098, 25.0, 67.0, 0.9968, 3.2, 0.68, 9.8] => 0 (expected 0)\n",
      "[7.8, 0.76, 0.04, 2.3, 0.092, 15.0, 54.0, 0.997, 3.26, 0.65, 9.8] => 0 (expected 0)\n",
      "[11.2, 0.28, 0.56, 1.9, 0.075, 17.0, 60.0, 0.998, 3.16, 0.58, 9.8] => 0 (expected 1)\n",
      "[7.4, 0.7, 0.0, 1.9, 0.076, 11.0, 34.0, 0.9978, 3.51, 0.56, 9.4] => 0 (expected 0)\n",
      "[7.4, 0.66, 0.0, 1.8, 0.075, 13.0, 40.0, 0.9978, 3.51, 0.56, 9.4] => 0 (expected 0)\n",
      "[7.9, 0.6, 0.06, 1.6, 0.069, 15.0, 59.0, 0.9964, 3.3, 0.46, 9.4] => 0 (expected 0)\n",
      "[7.3, 0.65, 0.0, 1.2, 0.065, 15.0, 21.0, 0.9946, 3.39, 0.47, 10.0] => 0 (expected 1)\n",
      "[7.8, 0.58, 0.02, 2.0, 0.073, 9.0, 18.0, 0.9968, 3.36, 0.57, 9.5] => 0 (expected 1)\n",
      "[7.5, 0.5, 0.36, 6.1, 0.071, 17.0, 102.0, 0.9978, 3.35, 0.8, 10.5] => 0 (expected 0)\n",
      "[6.7, 0.58, 0.08, 1.8, 0.097, 15.0, 65.0, 0.9959, 3.28, 0.54, 9.2] => 0 (expected 0)\n",
      "[7.5, 0.5, 0.36, 6.1, 0.071, 17.0, 102.0, 0.9978, 3.35, 0.8, 10.5] => 0 (expected 0)\n",
      "[5.6, 0.615, 0.0, 1.6, 0.08900000000000001, 16.0, 59.0, 0.9943, 3.58, 0.52, 9.9] => 0 (expected 0)\n",
      "[7.8, 0.61, 0.29, 1.6, 0.114, 9.0, 29.0, 0.9974, 3.26, 1.56, 9.1] => 1 (expected 0)\n",
      "[8.9, 0.62, 0.18, 3.8, 0.17600000000000002, 52.0, 145.0, 0.9986, 3.16, 0.88, 9.2] => 0 (expected 0)\n",
      "[8.9, 0.62, 0.19, 3.9, 0.17, 51.0, 148.0, 0.9986, 3.17, 0.93, 9.2] => 0 (expected 0)\n",
      "[8.5, 0.28, 0.56, 1.8, 0.092, 35.0, 103.0, 0.9969, 3.3, 0.75, 10.5] => 0 (expected 1)\n",
      "[8.1, 0.56, 0.28, 1.7, 0.368, 16.0, 56.0, 0.9968, 3.11, 1.28, 9.3] => 0 (expected 0)\n"
     ]
    }
   ],
   "source": [
    "# summarize the first 5 cases\n",
    "for i in range(18):\n",
    "    print('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
